# -*- coding: utf-8 -*-
"""Churn.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1E4wzKuq6FnYDzV7AQ5JjQCUZv8UCzMKG
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from collections import Counter


from sklearn import pipeline
from sklearn import metrics
from sklearn.model_selection import train_test_split
from sklearn import ensemble
from sklearn import preprocessing
from sklearn import tree
from sklearn.model_selection import GridSearchCV
from sklearn.linear_model import LogisticRegressionCV


from feature_engine import imputation
from feature_engine import encoding

def report_model(X, y, model, metric, is_prob=True):
    if is_prob:
        y_pred = model.predict_proba(X)[:,1]
    
    else:
        y_pred = model.predict(X)
    res = metric(y, y_pred)
    return res

"""##**Importing Dataset**##"""

df = pd.read_csv('/content/drive/MyDrive/Data Science/Kaggle/Churn/churn.csv', index_col='customerID')
df = df.replace(r'^\s*$', np.nan, regex=True)
df.head()

df.info()

df.describe()

df.shape

#changing dependent variable format
df['Churn'] = df['Churn'].replace({'No': 0, 'Yes': 1})
df.head()

"""##**Train and Test Split**##"""

features = df.columns.tolist()[:-1]
target = 'Churn'

X_train, X_test , y_train, y_test = train_test_split(df[features],
                                                     df[target],
                                                     random_state=42,
                                                     test_size=0.25)

print(f"Training target statistics: {Counter(y_train)}")
print(f"Testing target statistics: {Counter(y_test)}")

print('X_train: ' ,X_train.shape)
print('X_test: ' ,X_test.shape)
print('y_train: ' ,y_train.shape)
print('y_test: ' ,y_test.shape)

"""##**Exploring Training Set**##"""

X_train.info()

X_train['TotalCharges'] = X_train['TotalCharges'].replace(' ', np.nan, regex=True).astype(float)
missing_total = X_train['TotalCharges'].isnull().sum()
print('Missing Values from Total Charges: ',missing_total)

"""##**Univariate Analisys**##"""

#customers retained and lost

retained = y_train[y_train == 1].shape[0]
lost = y_train[y_train == 0].shape[0]

retained_pct = (retained / (retained + lost))
lost_pct = (1 - retained_pct)

print(f'Percentage of clients lost: {round(lost_pct*100, 2)} %')
print(f'Percentage of cliets retained: {round(retained_pct*100, 2)} % ')

y_train.value_counts().plot(kind='bar')
plt.title('Customers Churn')
plt.show()

#Monthly Charges
X_train['MonthlyCharges'].plot(kind='kde', subplots=False, layout=(1, 8))
plt.xlim([0,175])
plt.xlabel('Monthly Price ($)')
plt.show()
print('Monthly Charges Mean: ',X_train['MonthlyCharges'].mean())

#Payment Methods
X_train['PaymentMethod'].value_counts()

X_train['PaymentMethod'].value_counts().plot(kind='bar')
plt.title('Payment Methods')
plt.show()

#Contract Type
X_train['Contract'].value_counts()

"""##**Multivariate Analysis**##"""

#Churn per payment method
sns.countplot('Churn', hue='PaymentMethod',data=df)
plt.show()

#Churn density x monthly price and  number of months

fig, axes = plt.subplots(1,2, sharey = True, figsize = (10,8))

axes[0].set_title('Density of Churn Cases x Monthly Charges')
sns.distplot(df[df['Churn'] == 1]['MonthlyCharges'], hist=True, color='blue', ax = axes[0])

axes[1].set_title('Density of Churn Cases x Tenure')
axes[1].set_xlim(0,80)
sns.distplot(df[df['Churn'] == 1]['tenure'], hist=True, color='orange', ax = axes[1])

plt.show()

pd.plotting.scatter_matrix(X_train, figsize=(10,10))
plt.figure()
plt.show()

_ = sns.pairplot(X_train, hue="Contract", height=2, diag_kind="kde")
plt.show()

"""##**Outlier Detection**##"""

#function for outlier detection - #Criteria: Data points that lie 1.5 times of IQR above Q3 and below Q1 are outliers

outliers = []
def detect_outliers_iqr(data):
    data = sorted(data)
    q1 = np.percentile(data, 25)
    q3 = np.percentile(data, 75)
    # print(q1, q3)
    IQR = q3-q1
    lwr_bound = q1-(1.5*IQR)
    upr_bound = q3+(1.5*IQR)
    # print(lwr_bound, upr_bound)
    for i in data: 
        if (i<lwr_bound or i>upr_bound):
            outliers.append(i)
    return outliers# Driver code

for feature in ['tenure','MonthlyCharges','TotalCharges']:

  sample_outliers = detect_outliers_iqr(X_train[feature])
  print(f"Outliers from {feature} : ", sample_outliers)

list_out = ['tenure','TotalCharges','MonthlyCharges']

fig, axes = plt.subplots(1,len(list_out), figsize = (10,8))

for i, feature in enumerate(list_out):
 
  axes[i].set_title(f'Outliers on {feature}')
  axes[i].boxplot(X_train[feature].dropna())

plt.show()

"""##**Feature Engineering Pipeline**##"""

cat_features = X_train.dtypes[X_train.dtypes=='object'].index.tolist()
num_features = list(set(X_train.columns) - set(cat_features))

#encoding
onehot = encoding.OneHotEncoder(drop_last=True, variables=cat_features)

#imputing median value on NaN ocurrencies
imput = imputation.MeanMedianImputer(imputation_method='median', variables='TotalCharges')

#classifier
rf_clf = ensemble.RandomForestClassifier(n_estimators=200, min_samples_leaf=50, n_jobs=-1, random_state=42)

#defining a pipeline
model_pipe = pipeline.Pipeline(steps=[
                                      ('One Hot', onehot),
                                      ('Imput', imput),
                                      ('Model', rf_clf)])

model_pipe.fit(X_train, y_train)

#Features importance
print('Feature importance by model ...')
features_transformed = model_pipe[:-1].transform(df[features]).columns.tolist()
features_importance = pd.DataFrame(model_pipe[-1].feature_importances_, index=features_transformed)
features_importance.sort_values(by=0, ascending=False)

#features with less than 0.05 of importance will be cut from the model
new_features = ['Contract','tenure', 'TotalCharges', 'OnlineSecurity', 'TechSupport' ,'InternetService','PaymentMethod','MonthlyCharges']

X_train, X_test , y_train, y_test = train_test_split(df[new_features],
                                                     df[target],
                                                     random_state=42,
                                                     test_size=0.25,
                                                     stratify=df[target])

X_train['TotalCharges'] = X_train['TotalCharges'].replace(' ', np.nan, regex=True).astype(float)

cat_features = X_train.dtypes[X_train.dtypes=='object'].index.tolist()
num_features = list(set(X_train.columns) - set(cat_features))

#features with less than 0.05 of importance will be cut from the model
new_features = ['Contract','tenure', 'TotalCharges', 'OnlineSecurity', 'TechSupport' ,'InternetService','PaymentMethod','MonthlyCharges']

X_train, X_test , y_train, y_test = train_test_split(df[new_features],
                                                     df[target],
                                                     random_state=42,
                                                     test_size=0.25,
                                                     stratify=df[target])

X_train['TotalCharges'] = X_train['TotalCharges'].replace(' ', np.nan, regex=True).astype(float)

cat_features = X_train.dtypes[X_train.dtypes=='object'].index.tolist()
num_features = list(set(X_train.columns) - set(cat_features))

#encoding
onehot = encoding.OneHotEncoder(drop_last=True, variables = cat_features)

#imputing median value of NaN
imput = imputation.MeanMedianImputer(imputation_method='median', variables ='TotalCharges' )

#decision tree classifier
dt_clf = tree.DecisionTreeClassifier(max_depth=15,
                            min_samples_leaf=50,
                            random_state=42)

#gridsearch - Decision Tree
params = {'max_depth': [5,15,25,35,45,50],
          'min_samples_leaf': [5,10,20,40,60,80,100]}

grid_search = GridSearchCV(dt_clf,
                          params,
                           n_jobs=1,
                           cv=4,
                           scoring='roc_auc',
                           verbose=0,
                           refit=True)

#redefining the pipeline
model_pipe = pipeline.Pipeline(steps=[
                                      ('OneHot', onehot),
                                      ('Imput', imput),
                                      ('Model', grid_search)])

model_pipe.fit(X_train, y_train)

print('Baseline:', round((1 - y_train.mean())*100, 2))

auc_train = report_model(X_train, y_train, model_pipe, metrics.roc_auc_score)
auc_test = report_model(X_test, y_test, model_pipe, metrics.roc_auc_score)

print("auc_train:", auc_train)
print("auc_test:", auc_test)

y_train_pred = model_pipe.predict(X_train)
y_train_prob = model_pipe.predict_proba(X_train)

acc_train = metrics.accuracy_score(y_train, y_train_pred)
roc_train = metrics.roc_auc_score(y_train, y_train_prob[:, 1])
print(metrics.classification_report(y_train, y_train_pred))

y_test_pred = model_pipe.predict(X_test)
y_test_prob = model_pipe.predict_proba(X_test)
print(metrics.classification_report(y_test, y_test_pred))